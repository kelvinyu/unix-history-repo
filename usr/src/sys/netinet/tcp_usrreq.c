/* tcp_usrreq.c 1.26 81/11/08 */

#include "../h/param.h"
#include "../h/systm.h"
#include "../h/mbuf.h"
#include "../h/socket.h"
#include "../h/socketvar.h"
#include "../h/protosw.h"
#include "../net/inet.h"
#include "../net/inet_systm.h"
#include "../net/imp.h"
#include "../net/ip.h"
#include "../net/tcp.h"
#define TCPFSTAB
#ifdef TCPDEBUG
#define TCPSTATES
#endif
#include "../net/tcp_fsm.h"
#include "../net/tcp_var.h"
#include "/usr/include/errno.h"

struct	tcb *tcp_attach();

/*
 * Tcp initialization
 */
tcp_init()
{

	tcp_iss = 1;		/* wrong */
	tcb.tcb_next = tcb.tcb_prev = (struct tcb *)&tcb;
}

/*
 * Tcp finite state machine entries for timer and user generated
 * requests.  These routines raise the ipl to that of the network
 * to prevent reentry.  In particluar, this requires that the software
 * clock interrupt have lower priority than the network so that
 * we can enter the network from timeout routines without improperly
 * nesting the interrupt stack.
 */

/*
 * Tcp protocol timeout routine called every 500 ms.
 * Updates the timers in all active tcb's and
 * causes finite state machine actions if timers expire.
 */
tcp_slowtimo()
{
	register struct tcb *tp;
	int s = splnet();
	register short *tmp;
	register int i;
COUNT(TCP_TIMEO);

	/*
	 * Search through tcb's and update active timers.
	 */
	tp = tcb.tcb_next;
	for (; tp != (struct tcb *)&tcb; tp = tp->tcb_hd.tcb_next) {
		tmp = &tp->t_init;
		for (i = 0; i < TNTIMERS; i++) {
			if (*tmp && --*tmp == 0)
				tcp_usrreq(tp->t_socket, PRU_SLOWTIMO, 0, i);
			tmp++;
		}
		tp->t_xmt++;
	}
	tcp_iss += ISSINCR/2;		/* increment iss */
	splx(s);
}

/*
 * Cancel all timers for tcp tp.
 */
tcp_tcancel(tp)
	struct tcb *tp;
{
	register short *tmp = &tp->t_init;
	register int i;

	for (i = 0; i < TNTIMERS; i++)
		*tmp++ = 0;
}

/*
 * Process a TCP user request for tcp tb.  If this is a send request
 * then m is the mbuf chain of send data.  If this is a timer expiration
 * (called from the software clock routine), then timertype tells which timer.
 */
tcp_usrreq(so, req, m, addr)
	struct socket *so;
	int req;
	struct mbuf *m;
	caddr_t addr;
{
	register struct tcb *tp = (struct tcb *)so->so_pcb;
	int s = splnet();
	register int nstate;
#ifdef TCPDEBUG
	struct tcp_debug tdb;
#endif
	int error = 0;
COUNT(TCP_USRREQ);

	if (tp) {
		nstate = tp->t_state;
		tp->tc_flags &= ~TC_NET_KEEP;
	} else 
		if (req != PRU_ATTACH)
			return (ENOTCONN);
#ifdef KPROF
	acounts[nstate][req]++;
#endif
#ifdef TCPDEBUG
	if (tp && ((tp->t_socket->so_options & SO_DEBUG) || tcpconsdebug)) {
		tdb_setup(tp, (struct th *)0, req, &tdb);
		tdb.td_tim = timertype;
	} else
		tdb.td_tod = 0;
#endif
	switch (req) {

	/*
	 * Attach a tcp control block to this socket.
	 * TCP is not multicast, so this is possible
	 * only if no connection currently exists.
	 */
	case PRU_ATTACH:
		if (tp)
			error = EISCONN;
		else
			tp = tcp_attach(so, &error);
		nstate = CLOSED;
		break;

	/*
	 * Detach the TCP from this socket.  This
	 * is possible only if a connection currently exists.
	 */
	case PRU_DETACH:
		so->so_pcb = 0;
		break;

	/*
	 * Form connection: send a SYN.
	 */
	case PRU_CONNECT:
		if (nstate != 0 && nstate != CLOSED)
			goto bad;
		tcp_sndctl(tp);
		nstate = SYN_SENT;
		break;

	case PRU_DISCONNECT:
		so->so_pcb = 0;
		tcp_destroy(tp);
		break;

	/*
	 * Declare no further transmissions.
	 * Can be generated by a user ioctl (half-close),
	 * or when higher level close occurs, if a close hasn't happened
	 * already.
	 */
	case PRU_SHUTDOWN:
		switch (nstate) {

		/*
		 * If we are aborting out of a listener or a active
		 * connection which has not yet completed we can just
		 * delete the tcb.
		 */
		case LISTEN:
		case SYN_SENT:
			nstate = CLOSED;
			break;

		/*
		 * If we have gotten as far as receiving a syn from
		 * our foreign peer, we must be sure to send a FIN.
		 * If we have gotten a FIN from the foreign peer already
		 * (CLOSE_WAIT state), then all that remains is to wait
		 * for his ack of the FIN (LAST_ACK state).  If we have
		 * not gotten a FIN from the foreign peer then we need
		 * to either:
		 *	1. rcv ack of our FIN (to FIN_W2) and then
		 *	   send an ACK (to TIME_WAIT) and timeout at 2*MSL.
		 * or	2. receive hist FIN (to CLOSING), send an ACK
		 *	   (to TIME_WAIT), and then timeout.
		 * In any case this starts with a transition to FIN_W1 here.
		 */
		case SYN_RCVD:
		case L_SYN_RCVD:
		case ESTAB:	
		case CLOSE_WAIT:
			tp->tc_flags |= TC_SND_FIN;
			tcp_sndctl(tp);
			tp->tc_flags |= TC_USR_CLOSED;
			nstate = nstate != CLOSE_WAIT ? FIN_W1 : LAST_ACK;
			break;
			
		/*
		 * In these states the user has already closed;
		 * trying to close again is an error.
		 */
		case FIN_W1:
		case FIN_W2:
		case TIME_WAIT:
		case CLOSING:
		case LAST_ACK:
		case RCV_WAIT:
			break;

		default:
			goto bad;
		}
		break;

	/*
	 * User notification of more window availability after
	 * reading out data.  This should not happen before a connection
	 * is established or after it is closed.
	 * If the foreign peer has closed and the local entity
	 * has not, inform him of the FIN (give end of file).
	 * If the local entity is in RCV_WAIT state (draining data
	 * out of the TCP buffers after foreign close) and there
	 * is no more data, institute a close.
	 */
	case PRU_RCVD:
		if (nstate < ESTAB || nstate == CLOSED)
			goto bad;
		tcp_sndwin(tp);
		if ((tp->tc_flags&TC_FIN_RCVD) &&
		    (tp->tc_flags&TC_USR_CLOSED) == 0 &&
		    rcv_empty(tp))
			tcp_error(tp, ESHUTDOWN);
		if (nstate == RCV_WAIT && rcv_empty(tp))
			nstate = CLOSED;
		break;

	/*
	 * Send request on open connection.
	 * Should not happen if the connection is not yet established.
	 * Allowed only on ESTAB connection and after FIN from
	 * foreign peer.
	 */
	case PRU_SEND:
		switch (nstate) {

		case ESTAB:
		case CLOSE_WAIT:
			nstate = tcp_usrsend(tp, m);
			break;
		
		default:
			if (nstate < ESTAB)
				goto bad;
			m_freem(m);
			/* tcp_user(tp, UCLSERR); */
			break;
		}
		break;

	/*
	 * User abort of connection.
	 * If a SYN has been received, but we have not exchanged FINs
	 * then we need to send an RST.  In any case we then 
	 * enter closed state.
	 */
	case PRU_ABORT:
		if (nstate == 0 || nstate == CLOSED)
			break;
		switch (nstate) {

		case 0:
		case CLOSED:
			break;

		case SYN_RCVD:
		case ESTAB:
		case FIN_W1:
		case FIN_W2:
		case CLOSE_WAIT:
			tp->tc_flags |= TC_SND_RST;
			tcp_sndnull(tp);
			/* fall into ... */

		default:
			nstate = CLOSED;
		}
		break;

	/*
	 * Network down entry.  Discard the tcb and force
	 * the state to be closed, ungracefully.
	 */
	case PRU_CLEAR:
		if (nstate == 0 || nstate == CLOSED)
			break;
		nstate = CLOSED;
		break;

	/*
	 * Ioctl on protocols.
	 */
	case PRU_CONTROL:
		break;

	/*
	 * TCP Timer processing.
	 * Timers should expire only on open connections
	 * not in LISTEN state.
	 */
	case PRU_SLOWTIMO:
		switch (nstate) {

		case 0:
		case CLOSED:
		case LISTEN:
			goto bad;

		default:
			nstate = tcp_timers(tp, (int)addr);
		}
		break;

	default:
		panic("tcp_usrreq");
	bad:
		printf("tcp: bad state: tcb=%x state=%d input=%d\n",
		    tp, tp->t_state, req);
		nstate = EFAILEC;
		break;
	}
#ifdef TCPDEBUG
	if (tdb.td_tod)
		tdb_stuff(&tdb, nstate);
#endif
	/* YECH */
	switch (nstate) {

	case CLOSED:
	case SAME:
		break;

	case EFAILEC:
		if (m)
			m_freem(dtom(m));
		break;

	default:
		tp->t_state = nstate;
		break;
	}
	splx(s);
}

tcp_sense()
{

}

/*
 * Open routine, called to initialize newly created tcb fields.
 */
struct tcb *
tcp_attach(so)
	register struct socket *so;
{
	register struct tcb *tp;
COUNT(TCP_ATTACH);

	/*
	 * Link in tcb queue and make
	 * initialize empty reassembly queue.
	 */
	tp->tcb_hd.tcb_next = tcb.tcb_next;
	tcb.tcb_next->tcb_hd.tcb_prev = tp;
	tp->tcb_hd.tcb_prev = (struct tcb *)&tcb;
	tcb.tcb_next = tp;
	tp->tcb_hd.seg_next = tp->tcb_hd.seg_prev = (struct th *)tp;

	/*
	 * Initialize sequence numbers and
	 * round trip retransmit timer.
	 * (Other fields were init'd to zero when tcb allocated.)
	 */
	tp->t_xmtime = T_REXMT;
	tp->snd_end = tp->seq_fin = tp->snd_nxt = tp->snd_hi = tp->snd_una =
	    tp->iss = tcp_iss;
	tp->snd_off = tp->iss + 1;
	tcp_iss += (ISSINCR >> 1) + 1;
}

/*
 * Destroy a tcb.
 */
tcp_detach(tp)
	register struct tcb *tp;
{
	register struct socket *so = tp->t_socket;
	register struct th *t;
	register struct mbuf *m;
COUNT(TCP_DETACH);

	/*
	 * Remove from tcb queue and cancel timers.
	 */
	tp->tcb_hd.tcb_prev->tcb_hd.tcb_next = tp->tcb_hd.tcb_next;
	tp->tcb_hd.tcb_next->tcb_hd.tcb_prev = tp->tcb_hd.tcb_prev;
	tcp_tcancel(tp);

	/*
	 * Discard all buffers.
	 */
	for (t = tp->tcb_hd.seg_next; t != (struct th *)tp; t = t->t_next)
		m_freem(dtom(t));
	if (so->so_rcv.sb_mb)
	    { m_freem(so->so_rcv.sb_mb); so->so_rcv.sb_mb = 0; }
	so->so_rcv.sb_cc = 0; so->so_rcv.sb_mbcnt = 0;
	if (so->so_snd.sb_mb)
	    { m_freem(so->so_snd.sb_mb); so->so_rcv.sb_mb = 0; }
	so->so_snd.sb_cc = 0; so->so_snd.sb_mbcnt = 0;

	for (m = tp->seg_unack; m; m = m->m_act)
		m_freem(m);
	tp->seg_unack = 0;

	/*
	 * Free routing table entry.
	 */
	if (tp->t_host) {
		h_free(tp->t_host);
		tp->t_host = 0;
	}

	/*
	 * Free tcp send template, the tcb itself,
	 * and the space we had reserved in the meory pool.
	 */
	if (tp->t_template) {
		m_free(dtom(tp->t_template));
		tp->t_template = 0;
	}
	wmemfree((caddr_t)tp, 1024);
	m_release(so->so_rcv.sb_hiwat + so->so_snd.sb_hiwat + 2 * MSIZE);
}

/*
 * Send data queue headed by m0 into the protocol.
 */
tcp_usrsend(tp, m0)
	register struct tcb *tp;
	struct mbuf *m0;
{
	register struct mbuf *m, *n;
	register struct socket *so = tp->t_socket;
	register off;
	seq_t last;
COUNT(TCP_USRSEND);

	last = tp->snd_off;
	for (m = n = m0; m != NULL; m = m->m_next) {
		so->so_snd.sb_mbcnt++;
		if (m->m_off > MMAXOFF)
			so->so_snd.sb_mbcnt += NMBPG;
		last += m->m_len;
	}
	if ((m = so->so_snd.sb_mb) == NULL)
		so->so_snd.sb_mb = n;
	else {
		while (m->m_next != NULL) {
			m = m->m_next;
			last += m->m_len;
		}
		if (m->m_off <= MMAXOFF) {
			last += m->m_len;
			off = m->m_off + m->m_len;
			while (n && n->m_off <= MMAXOFF &&
			    (MMAXOFF - off) >= n->m_len) {
				bcopy((caddr_t)((int)n + n->m_off),
				      (caddr_t)((int)m + off), n->m_len);
				m->m_len += n->m_len;
				off += n->m_len;
				so->so_snd.sb_mbcnt--;
				n = m_free(n);
			}
		}
		m->m_next = n;
	}
	if (tp->t_options & TO_EOL)
		tp->snd_end = last;
	if (tp->t_options & TO_URG) {
		tp->snd_urp = last+1;
		tp->tc_flags |= TC_SND_URG;
	}
	tcp_send(tp);
	return (SAME);
}

/*
 * TCP timer went off processing.
 */
tcp_timers(tp, timertype)
	register struct tcb *tp;
	int timertype;
{

COUNT(TCP_TIMERS);
	switch (timertype) {

	case TINIT:		/* initialization timer */
		if ((tp->tc_flags&TC_SYN_ACKED) == 0) {		/* 35 */
/* XXX */		/* tcp_close(tp, UINTIMO); */
			return (CLOSED);
		}
		return (SAME);

	case TFINACK:		/* fin-ack timer */
		switch (tp->t_state) {

		case TIME_WAIT:
			/*
			 * We can be sure our ACK of foreign FIN was rcvd,
			 * and can close if no data left for user.
			 */
			if (rcv_empty(tp)) {
/* XXX */			/* tcp_close(tp, UCLOSED); */	/* 14 */
				return (CLOSED);
			}
			return (RCV_WAIT);			/* 17 */

		case CLOSING:
			tp->tc_flags |= TC_WAITED_2_ML;
			return (SAME);

		default:
			return (SAME);
		}

	case TREXMT:		/* retransmission timer */
		if (tp->t_rexmt_val > tp->snd_una) {	 	/* 34 */
			/*
			 * Set so for a retransmission, increase rexmt time
			 * in case of multiple retransmissions.
			 */
			tp->snd_nxt = tp->snd_una;
			tp->tc_flags |= TC_REXMT;
			tp->t_xmtime = tp->t_xmtime << 1;
			if (tp->t_xmtime > T_REMAX)
				tp->t_xmtime = T_REMAX;
			tcp_send(tp);
		}
		return (SAME);

	case TREXMTTL:		/* retransmit too long */
		if (tp->t_rtl_val > tp->snd_una)		/* 36 */
/* XXX */		/* to_user(tp->t_socket, URXTIMO); */;
		/*
		 * If user has already closed, abort the connection.
		 */
		if (tp->tc_flags & TC_USR_CLOSED) {
/* XXX */		/* tcp_close(tp, URXTIMO); */
			return (CLOSED);
		}
		return (SAME);

	case TPERSIST:		/* persist timer */
		/*
		 * Force a byte send through closed window.
		 */
		tp->tc_flags |= TC_FORCE_ONE;
		tcp_send(tp);
		return (SAME);
	}
	panic("tcp_timers");
}

tcp_error(so, errno)
	struct socket *so;
	int errno;
{
COUNT(TO_USER);

	so->so_error = errno;
	sowakeup(so);
}

#ifdef TCPDEBUG
/*
 * TCP debugging utility subroutines.
 * THE NAMES OF THE FIELDS USED BY THESE ROUTINES ARE STUPID.
 */
tdb_setup(tp, n, input, tdp)
	struct tcb *tp;
	register struct th *n;
	int input;
	register struct tcp_debug *tdp;
{

COUNT(TDB_SETUP);
	tdp->td_tod = time;
	tdp->td_tcb = tp;
	tdp->td_old = tp->t_state;
	tdp->td_inp = input;
	tdp->td_tim = 0;
	tdp->td_new = -1;
	if (n) {
		tdp->td_sno = n->t_seq;
		tdp->td_ano = n->t_ackno;
		tdp->td_wno = n->t_win;
		tdp->td_lno = n->t_len;
		tdp->td_flg = n->th_flags;
	} else
		tdp->td_sno = tdp->td_ano = tdp->td_wno = tdp->td_lno =
		    tdp->td_flg = 0;
}

tdb_stuff(tdp, nstate)
	struct tcp_debug *tdp;
	int nstate;
{
COUNT(TDB_STUFF);

	tdp->td_new = nstate;
	tcp_debug[tdbx++ % TDBSIZE] = *tdp;
	if (tcpconsdebug & 2)
		tcp_prt(tdp);
}

tcp_prt(tdp)
	register struct tcp_debug *tdp;
{
COUNT(TCP_PRT);

	printf("%x ", ((int)tdp->td_tcb)&0xffffff);
	if (tdp->td_inp == INSEND) {
		printf("SEND #%x", tdp->td_sno);
		tdp->td_lno = ntohs(tdp->td_lno);
		tdp->td_wno = ntohs(tdp->td_wno);
	} else {
		if (tdp->td_inp == INRECV)
			printf("RCV #%x ", tdp->td_sno);
		printf("%s.%s",
		    tcpstates[tdp->td_old], tcpinputs[tdp->td_inp]);
		if (tdp->td_inp == ISTIMER)
			printf("(%s)", tcptimers[tdp->td_tim]);
		printf(" -> %s",
		    tcpstates[(tdp->td_new > 0) ? tdp->td_new : tdp->td_old]);
		if (tdp->td_new == -1)
			printf(" (FAILED)");
	}
	/* GROSS... DEPENDS ON SIGN EXTENSION OF CHARACTERS */
	if (tdp->td_lno)
		printf(" len=%d", tdp->td_lno);
	if (tdp->td_wno)
		printf(" win=%d", tdp->td_wno);
	if (tdp->td_flg & TH_FIN) printf(" FIN");
	if (tdp->td_flg & TH_SYN) printf(" SYN");
	if (tdp->td_flg & TH_RST) printf(" RST");
	if (tdp->td_flg & TH_EOL) printf(" EOL");
	if (tdp->td_flg & TH_ACK)  printf(" ACK %x", tdp->td_ano);
	if (tdp->td_flg & TH_URG) printf(" URG");
	printf("\n");
}
#endif
